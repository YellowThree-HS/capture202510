"""
æ¯å­æ£€æµ‹å’Œä½å§¿ä¼°è®¡å‡½æ•°
åŠŸèƒ½ï¼šä¼ å…¥RGBå›¾å’Œæ·±åº¦å›¾ï¼Œè¯†åˆ«å›¾ç‰‡æ£€æµ‹æ¯å­å¹¶åˆ†å‰²ï¼Œæœ€åè¿”å›ä½å§¿
åŒ…å«æ‰‹çœ¼æ ‡å®šçŸ©é˜µ
"""

import cv2
import numpy as np
import os
from lib.camera import Camera
from lib.yolo_and_sam import YOLOSegmentator
from lib.mask2pose import mask2pose, draw_pose_axes


def detect_cup_pose(cam, conf_threshold=0.1, robot_matrix=None):
    """
    æ£€æµ‹æ¯å­å¹¶è¿”å›ä½å§¿
    
    å‚æ•°:
        cam: å·²åˆå§‹åŒ–çš„ç›¸æœºå¯¹è±¡
        conf_threshold: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé»˜è®¤0.1
        robot_matrix: æœºæ¢°è‡‚ä½å§¿çŸ©é˜µï¼Œå¯é€‰
    
    è¿”å›:
        dict: {
            'success': bool,  # æ˜¯å¦æˆåŠŸæ£€æµ‹åˆ°æ¯å­
            'pose': [x, y, z, roll, pitch, yaw] or None,  # æ¯å­ä½å§¿ (ç±³, åº¦)
            'pose_matrix': np.ndarray or None,  # 4x4ä½å§¿å˜æ¢çŸ©é˜µ
            'detection_info': dict or None,  # æ£€æµ‹ä¿¡æ¯
            'error_message': str or None  # é”™è¯¯ä¿¡æ¯
        }
    """
    try:
        # 1. å…ˆæ‹æ‘„ä¸€å¼ æ–°å›¾ç‰‡
        # print("\nğŸ“¸ æ‹æ‘„æ–°å›¾ç‰‡...")
        # saved_paths = cam.capture(
        #     save_dir="captured_images",
        #     prefix="auto_capture",
        #     save_color=True,
        #     save_depth=True,
        #     save_depth_colormap=True
        # )
        # # 2. å¤„ç†è¾“å…¥å›¾åƒ
        # color_image = cv2.imread(saved_paths['color'])
        # depth_image_array = cv2.imread(saved_paths['depth'], cv2.IMREAD_UNCHANGED)
        color_image, depth_image = cam.get_frames()

    
        color_filename = f'capture/color.png'
        depth_filename = f'capture/depth.png'

        cv2.imwrite(color_filename, color_image)
        cv2.imwrite(depth_filename, depth_image)

        if color_image is None:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': None,
                'error_message': f"æ— æ³•è¯»å–RGBå›¾åƒ: {color_image['color']}"
            }
        
        if depth_image is None:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': None,
                'error_message': f"æ— æ³•è¯»å–æ·±åº¦å›¾åƒ: {depth_image['depth']}"
            }
        
        # 3. å¤„ç†æ·±åº¦å›¾åƒæ ¼å¼
        if len(depth_image.shape) == 3:
            print("æ·±åº¦å›¾æ˜¯3é€šé“ï¼Œå–ç¬¬ä¸€ä¸ªé€šé“")
            depth_image = depth_image[:, :, 0]

        # è½¬æ¢ä¸ºæµ®ç‚¹æ•°å¹¶ä½¿ç”¨æ­£ç¡®çš„æ·±åº¦æ¯”ä¾‹è½¬æ¢ä¸ºç±³
        # RealSense D405çš„æ·±åº¦æ¯”ä¾‹æ˜¯0.0001
        depth_scale = 0.0001
        depth_image = depth_image.astype(np.float32) * depth_scale

        # 4. åˆå§‹åŒ–æ£€æµ‹å™¨
        categories_to_find = ['cup']
        segmentator = YOLOSegmentator()
        
        # 5. æ£€æµ‹å’Œåˆ†å‰²æ¯å­
        print(f"\nğŸ” å¼€å§‹æ£€æµ‹æ¯å­...")
        print(f"  å›¾åƒå°ºå¯¸: {color_image.shape}")
        print(f"  æ£€æµ‹ç±»åˆ«: {categories_to_find}")
        print(f"  ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
        
        result = segmentator.detect_and_segment_all(
            image=color_image,
            categories=categories_to_find,
            save_result=False,
            conf=conf_threshold
        )
        
        # 6. æ£€æŸ¥æ£€æµ‹ç»“æœ
        if not result['success']:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': None,
                'error_message': "æ£€æµ‹å¤±è´¥ï¼šæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“"
            }
        
        if 'objects' not in result or len(result['objects']) == 0:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': None,
                'error_message': "æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“"
            }
        
        # 7. å¤„ç†ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„æ¯å­
        cup_obj = result['objects'][0]
        print(f"\nğŸµ æ£€æµ‹åˆ°æ¯å­:")
        print(f"  ç±»åˆ«: {cup_obj['class']}")
        print(f"  ç½®ä¿¡åº¦: {cup_obj['confidence']:.2f}")
        print(f"  è¾¹ç•Œæ¡†: {cup_obj['bbox_xyxy']}")
        
        # 8. æ£€æŸ¥æ˜¯å¦æœ‰æ©ç 
        if cup_obj['mask'] is None:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': cup_obj,
                'error_message': "æœªè·å–åˆ°æ¯å­çš„åˆ†å‰²æ©ç "
            }
        
        print(f"  æ©ç å°ºå¯¸: {cup_obj['mask'].shape}")
        
        # 9. è·å–ç›¸æœºå†…å‚
        intrinsics = cam.get_camera_matrix()
        if intrinsics is None:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': cup_obj,
                'error_message': "æ— æ³•è·å–ç›¸æœºå†…å‚"
            }
        
        # 10. æ‰‹çœ¼æ ‡å®šçŸ©é˜µï¼ˆä»left_calibration.txtè¯»å–ï¼‰
        calibration_file = 'left_calibration.txt'
        if not os.path.exists(calibration_file):
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': cup_obj,
                'error_message': f"æ‰‹çœ¼æ ‡å®šæ–‡ä»¶ä¸å­˜åœ¨: {calibration_file}"
            }
        
        # è¯»å–æ‰‹çœ¼æ ‡å®šçŸ©é˜µ
        with open(calibration_file, 'r') as f:
            content = f.read().strip()
        
        # è§£æçŸ©é˜µæ•°æ® - å¤„ç†åµŒå¥—æ–¹æ‹¬å·æ ¼å¼
        # ç§»é™¤æœ€å¤–å±‚çš„æ–¹æ‹¬å·
        if content.startswith('[[') and content.endswith(']]'):
            content = content[1:-1]  # ç§»é™¤æœ€å¤–å±‚çš„æ–¹æ‹¬å·
        
        # æŒ‰è¡Œåˆ†å‰²
        lines = content.split('\n')
        matrix_data = []
        for line in lines:
            line = line.strip()
            if line.startswith('[') and line.endswith(']'):
                # ç§»é™¤æ–¹æ‹¬å·å¹¶åˆ†å‰²
                line = line[1:-1]
                row = [float(x.strip()) for x in line.split()]
                matrix_data.append(row)
        
        if len(matrix_data) != 4:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': cup_obj,
                'error_message': f"æ‰‹çœ¼æ ‡å®šçŸ©é˜µæ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›4x4çŸ©é˜µï¼Œå®é™…{len(matrix_data)}x{len(matrix_data[0]) if matrix_data else 0}"
            }
        
        hand_eye_matrix = np.array(matrix_data)
        
        # 11. ä¼°è®¡æ¯å­ä½å§¿
        print(f"\nğŸ“ å¼€å§‹ä½å§¿ä¼°è®¡...")
        pose, T_object2cam = mask2pose(
            mask=cup_obj['mask'],
            depth_image=depth_image,
            color_image=color_image,
            intrinsics=intrinsics,
            T_cam2base=None,  # åœ¨ç›¸æœºåæ ‡ç³»ä¸­è®¡ç®—
            object_class=cup_obj['class']
        )
        
        if pose is None or T_object2cam is None:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': cup_obj,
                'error_message': "ä½å§¿ä¼°è®¡å¤±è´¥"
            }
        
        print(f"  ç›¸æœºåæ ‡ç³»ä¸‹ä½ç½®: [{pose[0]:.3f}, {pose[1]:.3f}, {pose[2]:.3f}] ç±³")
        print(f"  ç›¸æœºåæ ‡ç³»ä¸‹å§¿æ€: [{pose[3]:.1f}Â°, {pose[4]:.1f}Â°, {pose[5]:.1f}Â°]")
        
        # 12. è½¬æ¢åˆ°æœºæ¢°è‡‚åŸºåæ ‡ç³»
        # ä½¿ç”¨ä¼ å…¥çš„æœºæ¢°è‡‚ä½å§¿çŸ©é˜µï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å•ä½çŸ©é˜µ
        if robot_matrix is not None:
            robot_pose_matrix = robot_matrix
        else:
            robot_pose_matrix = np.eye(4)
        pose_matrix = robot_pose_matrix @ hand_eye_matrix @ T_object2cam
        
        # 13. è½¬æ¢ä¸ºæœºæ¢°è‡‚åæ ‡ç³»ä¸‹çš„ä½å§¿
        from scipy.spatial.transform import Rotation as R
        rx, ry, rz = R.from_matrix(pose_matrix[:3, :3]).as_euler('xyz', degrees=True)
        x, y, z = pose_matrix[:3, 3] * 1000.0  # è½¬æ¢ä¸ºæ¯«ç±³
        ry = ry + 90  # æ ¹æ®å®é™…éœ€è¦è°ƒæ•´
        
        final_pose = [x, y, z, rx, ry, rz]
        
        print(f"\nâœ… ä½å§¿ä¼°è®¡å®Œæˆ:")
        print(f"  æœºæ¢°è‡‚åæ ‡ç³»ä¸‹ä½ç½®: [{x:.1f}, {y:.1f}, {z:.1f}] æ¯«ç±³")
        print(f"  æœºæ¢°è‡‚åæ ‡ç³»ä¸‹å§¿æ€: [{rx:.1f}Â°, {ry:.1f}Â°, {rz:.1f}Â°]")
        
        # 14. å¯è§†åŒ–ä½å§¿ï¼ˆå¯é€‰ï¼‰
        try:
            draw_pose_axes(color_image, intrinsics, T_object2cam)
        except Exception as e:
            print(f"ä½å§¿å¯è§†åŒ–å¤±è´¥: {e}")
        
        # 15. è¿”å›ç»“æœ
        return {
            'success': True,
            'pose': final_pose,
            'pose_matrix': pose_matrix,
            'detection_info': {
                'class': cup_obj['class'],
                'confidence': cup_obj['confidence'],
                'bbox_xyxy': cup_obj['bbox_xyxy'],
                'mask_shape': cup_obj['mask'].shape,
                'camera_pose': pose,
                'camera_pose_matrix': T_object2cam
            },
            'error_message': None
        }
        
    except Exception as e:
        return {
            'success': False,
            'pose': None,
            'pose_matrix': None,
            'detection_info': None,
            'error_message': f"å‡½æ•°æ‰§è¡Œå‡ºé”™: {str(e)}"
        }

def main():
    """
    ä¸»å‡½æ•° - åˆå§‹åŒ–ç›¸æœºå¹¶è¿è¡Œæ£€æµ‹
    """
    print("ğŸš€ æ¯å­æ£€æµ‹å’Œä½å§¿ä¼°è®¡ç¨‹åº")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç›¸æœº
    print("ğŸ“· åˆå§‹åŒ–ç›¸æœº...")
    try:
        cam = Camera(camera_model='D405')
        print("âœ… ç›¸æœºåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç›¸æœºåˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    try:
        # è°ƒç”¨æ£€æµ‹å‡½æ•°
        result = detect_cup_pose(cam, conf_threshold=0.1, robot_matrix=None)
        
        # è¾“å‡ºç»“æœ
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"  æˆåŠŸ: {result['success']}")
        
        if result['success']:
            print(f"  æ¯å­ä½å§¿: {result['pose']}")
            print(f"  æ£€æµ‹ä¿¡æ¯: {result['detection_info']}")
        else:
            print(f"  é”™è¯¯ä¿¡æ¯: {result['error_message']}")
        
        return result
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        return None
    finally:
        # é‡Šæ”¾ç›¸æœºèµ„æº
        print("\nğŸ”§ é‡Šæ”¾ç›¸æœºèµ„æº...")
        cam.release()
        print("âœ… ç¨‹åºç»“æŸ")



if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    main()
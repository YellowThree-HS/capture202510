import numpy as np
import cv2
import os
import csv
# import pupil_apriltags as apriltag
# from utils import frame_to_bgr_image
import transforms3d as tfs
import math
import random
import time
# import OrbbecCamera
# import robot_controller

from lib.dobot import DobotRobot
from lib.camera import Camera


def convert_euler_to_rotation_matrix(x, y, z, rx, ry, rz):
    """
    Convert Euler angles to a rotation matrix.
    Args:
    x, y, z: Translation coordinates.
    rx, ry, rz: Rotation angles in radians.

    Returns:
    A 4x4 rotation matrix.
    """
    rx = rx / math.pi * 180
    ry = ry / math.pi * 180
    rz = rz / math.pi * 180
    rmat = tfs.euler.euler2mat(math.radians(rx), math.radians(ry), math.radians(rz))
    rotation_matrix = tfs.affines.compose(np.squeeze(np.asarray((x, y, z))), rmat, [1, 1, 1])
    return rotation_matrix


def rotation_matrix_to_euler_angles(R):
    """
    Convert a rotation matrix to Euler angles.
    Args:
    R: A 3x3 rotation matrix.

    Returns:
    A tuple of Euler angles (phi, theta, psi).
    """
    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])
    singular = sy < 1e-6

    if not singular:
        x = math.atan2(R[2, 1], R[2, 2])
        y = math.atan2(-R[2, 0], sy)
        z = math.atan2(R[1, 0], R[0, 0])
    else:
        x = math.atan2(-R[1, 2], R[1, 1])
        y = math.atan2(-R[2, 0], sy)
        z = 0

    return np.array([x, y, z])

def hand_eye_calibration(
    R_end2base, 
    t_end2base, 
    R_board2camera, 
    t_board2camera, 
    method=cv2.CALIB_HAND_EYE_PARK
):
    """M_board2base
    æ‰‹çœ¼æ ‡å®šå°è£…å‡½æ•°
    
    å‚æ•°:
        R_end2base (list): æœºæ¢°è‡‚æœ«ç«¯åˆ°åŸºåº§çš„æ—‹è½¬çŸ©é˜µåˆ—è¡¨ [R1, R2, ...] (æ¯ä¸ªä¸º3x3 np.array)
        t_end2base (list): æœºæ¢°è‡‚æœ«ç«¯åˆ°åŸºåº§çš„å¹³ç§»å‘é‡åˆ—è¡¨ [t1, t2, ...] (æ¯ä¸ªä¸º3x1 np.array)
        R_board2camera (list): æ ‡å®šæ¿åˆ°ç›¸æœºçš„æ—‹è½¬çŸ©é˜µåˆ—è¡¨
        t_board2camera (list): æ ‡å®šæ¿åˆ°ç›¸æœºçš„å¹³ç§»å‘é‡åˆ—è¡¨
        method: æ ‡å®šæ–¹æ³• (é»˜è®¤PARKç®—æ³•)
        M_board2base_list (list): æ ‡å®šæ¿åˆ°åŸºåº§çš„é½æ¬¡å˜æ¢çŸ©é˜µåˆ—è¡¨ (4x4 np.array)
        
    è¿”å›ž:
        calibrate_mean (np.array): æ ‡å®šç»“æžœçš„å‡å€¼ (4x4 é½æ¬¡çŸ©é˜µ)
        calibrate_std (np.array): æ ‡å®šç»“æžœçš„æ ‡å‡†å·® (4x4 é½æ¬¡çŸ©é˜µ)
        M_cam2end (np.array): ç›¸æœºåˆ°æœ«ç«¯çš„é½æ¬¡å˜æ¢çŸ©é˜µ (4x4)
    """
    # 1. æ‰§è¡Œæ‰‹çœ¼æ ‡å®š
    R_cam2end, t_cam2end = cv2.calibrateHandEye(
        R_gripper2base=R_end2base,
        t_gripper2base=t_end2base,
        R_target2cam=R_board2camera,
        t_target2cam=t_board2camera,
        method=method
    )
    
    # 2. æž„å»ºç›¸æœºåˆ°æœ«ç«¯çš„é½æ¬¡å˜æ¢çŸ©é˜µ
    M_cam2end = np.eye(4)
    M_cam2end[:3, :3] = R_cam2end
    M_cam2end[:3, 3] = t_cam2end.reshape(3)

    M_end2base=np.eye(4)
    M_board2camera=np.eye(4)
    M_board2base=[]

    for sub_R_end2base,sub_t_end2base,sub_R_board2camera,sub_t_board2camera in zip(R_end2base, t_end2base, R_board2camera, t_board2camera):
        M_end2base[:3, :3] =sub_R_end2base
        M_end2base[:3, 3] =sub_t_end2base.reshape(3)
        M_board2camera[:3, :3] =sub_R_board2camera
        M_board2camera[:3, 3] =sub_t_board2camera.reshape(3)
        M_board2base.append(M_end2base@M_cam2end@M_board2camera)

    # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆæ³¨æ„ï¼šé½æ¬¡çŸ©é˜µçš„ç»Ÿè®¡éœ€åˆ†ç¦»æ—‹è½¬å’Œå¹³ç§»ï¼‰
    calibrate_mean = np.mean(M_board2base, axis=0)
    calibrate_std = np.std([np.linalg.norm(m[:3, 3]) for m in M_board2base])
    

    return calibrate_mean, calibrate_std, M_cam2end

def main(use_camera=True):
    """
    Main function to run the camera and robot control loop.
    """
    np.set_printoptions(suppress=True)
    # Auboi5Robot.initialize()
    # robot = robot_controller.URRobot()
    # handle = robot.create_context()
    # robot.connect('192.168.1.137', 8899)
    robot = DobotRobot("192.168.5.1", no_gripper=True)
    # è¿åŠ¨åˆ°åˆå§‹ä½å§¿
    init_joint_positions = np.array([-90.0, 0.0, -90.0, 0.0, 90.0, 90.0, 1.0])
    robot.moveJ(init_joint_positions)
    
    # cam=OrbbecCamera.OrbbecCamera(device_index=0)
    cam =  Camera(camera_model='d405')
    camera_matrix = cam.get_camera_matrix('color')
    distortion_coefficients = cam.get_distortion_coeffs('color')
    image_id = 0
    calibration_path = './Calibration_Pic/'
    os.makedirs(calibration_path, exist_ok=True)

    # camera_params = cam.rgb_intrinsic
    # distortion = cam.rgb_distortion
    # camera_matrix = np.array([[camera_params.fx, 0, camera_params.cx],
    #                           [0, camera_params.fy, camera_params.cy],
    #                           [0, 0, 1]], dtype=np.float64)
    # distortion_coefficients = np.array([distortion.k1, distortion.k2, distortion.p1,
                                        # distortion.p2, distortion.k3], dtype=np.float64)
    camera_matrix = cam.get_camera_matrix()
    distortion_coefficients = cam.get_distortion_coeffs()
    # åˆå§‹åŒ–å‚æ•°
    squaresX = 14
    squaresY = 9
    squareLength = 0.02
    markerLength = 0.015
    aruco_type = cv2.aruco.DICT_5X5_1000
    
    # åˆ›å»ºå­—å…¸å’Œæ ‡å®šæ¿å¯¹è±¡[17](@ref)
    dictionary = cv2.aruco.getPredefinedDictionary(aruco_type)
    board = cv2.aruco.CharucoBoard((squaresX, squaresY), squareLength, markerLength, dictionary)

    # åˆ›å»ºæ£€æµ‹å™¨å¯¹è±¡ï¼ˆæ–°ç‰ˆAPIï¼‰[6](@ref)
    aruco_params = cv2.aruco.DetectorParameters()
    aruco_detector = cv2.aruco.ArucoDetector(dictionary, aruco_params)

    # Lists to store transformation data
    robot_transforms, camera_transforms = [], []
    R_end2base, t_end2base, R_board2camera, t_board2camera = [], [], [], []
    M_board2base_list = []
    M_cam2end = np.eye(4)
    method={
        "TSAI":cv2.CALIB_HAND_EYE_TSAI,
        # "ANDREFF":cv2.CALIB_HAND_EYE_ANDREFF,
        "PARK":cv2.CALIB_HAND_EYE_PARK,
        "DANIILIDIS":cv2.CALIB_HAND_EYE_DANIILIDIS,
        "HORAUD":cv2.CALIB_HAND_EYE_HORAUD,
    }
    
    # ç§»åŠ¨æ­¥é•¿ï¼ˆæ¯«ç±³å’Œåº¦ï¼‰
    pos_step = 50.0   # ä½ç½®æ­¥é•¿ 10mm
    rot_step = 10.0    # æ—‹è½¬æ­¥é•¿ 5åº¦
    pos_step_fine = 1.0   # ç²¾ç»†ä½ç½®æ­¥é•¿ 1mm
    rot_step_fine = 1.0   # ç²¾ç»†æ—‹è½¬æ­¥é•¿ 1åº¦
    
    fine_mode = False  # ç²¾ç»†è°ƒæ•´æ¨¡å¼
    
    try:
        while True:
            try:
                color_image, _ = cam.get_frames()
            except Exception as e:
                print(e)
                continue
            undistorted_image = cv2.undistort(color_image, camera_matrix, distortion_coefficients)
            marker_corners, marker_ids, rejected = aruco_detector.detectMarkers(undistorted_image)
            image_copy = color_image.copy()

            # å¤„ç†æ£€æµ‹ç»“æžœ
            charuco_corners = []
            charuco_ids = []
            interpolated_corners = 0

            if marker_ids is not None and len(marker_ids) > 0:
                # æ’å€¼ChArUcoè§’ç‚¹[17](@ref)
                charuco_detector = cv2.aruco.CharucoDetector(board)
                charuco_corners, charuco_ids, _, _ = charuco_detector.detectBoard(undistorted_image)
                
                interpolated_corners = 0 if charuco_corners is None else len(charuco_corners)
                retval, rvec, tvec = cv2.aruco.estimatePoseCharucoBoard(charuco_corners, 
                                                                        charuco_ids, 
                                                                        board, 
                                                                        camera_matrix, 
                                                                        distortion_coefficients, None, None)
                
                # print("tvec", tvec)
                
                if rvec is not None and tvec is not None:
                    cv2.drawFrameAxes(image_copy, camera_matrix, distortion_coefficients, rvec, tvec, length=0.03)

            # ä¿å­˜å¹¶æ˜¾ç¤ºç»“æžœ
            cv2.imshow('Orbbec Camera', image_copy)
            key = cv2.waitKey(1)
            
            # ==================== é”®ç›˜æŽ§åˆ¶ ====================
            if key == 255:  # æ— æŒ‰é”®
                continue
                
            # èŽ·å–å½“å‰ä½å§¿
            curr_pose = robot.get_XYZrxryrz_state()
            original_pose = curr_pose.copy()
            step_pos = pos_step_fine if fine_mode else pos_step
            step_rot = rot_step_fine if fine_mode else rot_step
            moved = False
            
            # ä½ç½®æŽ§åˆ¶
            if key == ord('i') or key == ord('I'):  # Y+ å‰è¿›
                curr_pose[1] += step_pos
                moved = True
                # print(f"I: Y+ {step_pos}mm")
            elif key == ord('k') or key == ord('K'):  # Y- åŽé€€
                curr_pose[1] -= step_pos
                moved = True
                # print(f"K: Y- {step_pos}mm")
            elif key == ord('j') or key == ord('J'):  # X- å·¦ç§»
                curr_pose[0] -= step_pos
                moved = True
                # print(f"J: X- {step_pos}mm")
            elif key == ord('l') or key == ord('L'):  # X+ å³ç§»
                curr_pose[0] += step_pos
                moved = True
                # print(f"L: X+ {step_pos}mm")
            elif key == ord('w') or key == ord('W'):  # Z+
                curr_pose[2] += step_pos
                moved = True
                # print(f"W Z+ {step_pos}mm")
            elif key == ord('s') or key == ord('S'):  # Z-
                curr_pose[2] -= step_pos
                moved = True
                # print(f"S Z- {step_pos}mm")
                
            # å§¿æ€æŽ§åˆ¶
            elif key == ord('q') or key == ord('Q'):  # Rz+
                curr_pose[5] += step_rot
                moved = True
                # print(f"Q Rz+ {step_rot}Â°")
            elif key == ord('e') or key == ord('E'):  # Rz-
                curr_pose[5] -= step_rot
                moved = True
                # print(f"E Rz- {step_rot}Â°")
            elif key == ord('a') or key == ord('A'):  # Rx+
                curr_pose[3] += step_rot
                moved = True
                # print(f"A Rx+ {step_rot}Â°")
            elif key == ord('d') or key == ord('D'):  # Rx-
                curr_pose[3] -= step_rot
                moved = True
                # print(f"D Rx- {step_rot}Â°")
            elif key == ord('z') or key == ord('Z'):  # Ry+
                curr_pose[4] += step_rot
                moved = True
                # print(f"Z Ry+ {step_rot}Â°")
            elif key == ord('c') or key == ord('C'):  # Ry-
                curr_pose[4] -= step_rot
                moved = True
                # print(f"C Ry- {step_rot}Â°")   
                
            # æ‰§è¡Œç§»åŠ¨
            if moved:
                try:
                    robot.moveL(curr_pose)
                    # time.sleep(0.5)  # ç­‰å¾…è¿åŠ¨å®Œæˆ
                except Exception as e:
                    print(f"âš ï¸ ç§»åŠ¨å¤±è´¥: {e}")
                    print("ðŸ”„ å°è¯•å›žåˆ°åŽŸä½...")
                    robot.moveL(original_pose)
                    # time.sleep(0.5)
            
            if key == ord("r") or key == ord("R"):
                robot.moveJ(init_joint_positions)
            
            if key == 32:  # Space bar to capture data
                # robot_pose = robot.get_pose_axis()
                # print(robot_pose)
                R_charuco_to_camera, _ = cv2.Rodrigues(rvec)
                M_board2camera = np.eye(4)
                M_board2camera[:3, :3] = R_charuco_to_camera
                M_board2camera[:3, 3] = tvec.flatten()

                print(f"Saved data for image {image_id}")
                image_id += 1

                # # Convert poses to transformation matrices
                R_board2camera.append(M_board2camera[:3, :3])
                t_board2camera.append(M_board2camera[:3, 3])

                M_end2base = robot.get_pose_matrix()
                R_end2base.append(M_end2base[:3, :3])
                t_end2base.append(M_end2base[:3, 3])

                if len(t_end2base) > 5:
                    std_min=[]
                    M_list=[]
                    for calib_name,calib_method in method.items():
                        print("Calibration method:",calib_name)
                        breakpoint()
                        calib_mean, calib_std, M = hand_eye_calibration(R_end2base, t_end2base, R_board2camera, t_board2camera,calib_method)
                        print("mean:",calib_mean[:3, 3].T)
                        M_list.append(M)
                        std_min.append(calib_std)
                    print(M_list)
                    min_value = min(std_min)
                    print("min_value:",min_value)
                    if len(t_end2base) > 10 and 0.000001< min_value < 0.0015:
                        break

            elif key == 27:  # ESC to exit
                print("Program terminated")
                break
    except Exception as e:
        print('e:',e)
    finally:
        calib_mean=list(method.keys())[std_min.index(min_value)]
        best_M = M_list[std_min.index(min_value)]
        print("------------------------calib_mean:",calib_mean,"------------------------")
        print(best_M)
        np.savetxt("T_camera2end.txt", best_M)
        save_calibration_data(calibration_path, camera_transforms, robot_transforms)
        # ä¿å­˜å˜æ¢çŸ©é˜µåˆ°æ–‡ä»¶
        cv2.destroyAllWindows()

def draw_axis_on_image(image, tag, rvec, tvec, camera_matrix, distortion_coefficients):
    """
    Draw the axis on the image based on the tag pose.
    """
    axis_points = np.float32([[0.05, 0, 0], [0, 0.05, 0], [0, 0, -0.05]]).reshape(-1, 3)
    img_points, _ = cv2.projectPoints(axis_points, rvec, tvec, camera_matrix, distortion_coefficients)

    center = tuple(tag.center.astype(int))
    image = cv2.line(image, center, tuple(img_points[0].ravel().astype(int)), (255, 0, 0), 3)
    image = cv2.line(image, center, tuple(img_points[1].ravel().astype(int)), (0, 255, 0), 3)
    image = cv2.line(image, center, tuple(img_points[2].ravel().astype(int)), (0, 0, 255), 3)
    return image

def save_calibration_data(path, camera_data, robot_data):
    """
    Save the calibration data to CSV files.
    """
    with open(os.path.join(path, 'camera_data.csv'), 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerows(camera_data)

    with open(os.path.join(path, 'robot_data.csv'), 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerows(robot_data)

if __name__ == "__main__":
    main(use_camera=True)
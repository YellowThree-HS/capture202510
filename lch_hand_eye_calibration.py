import cv2
import numpy as np
import os
from lib.dobot import DobotRobot
from lib.camera import Camera
from scipy.spatial.transform import Rotation as R


save_path = "./collect_data/"
if not os.path.exists(save_path):
    os.makedirs(save_path, exist_ok=True)

def collect_data(T,color_image,count):
    
    x, y, z = T[:3, 3]
    euler = R.from_matrix(T[:3, :3]).as_euler('xyz', degrees=False)  # å¼§åº¦
    
    pose = [x, y, z] + list(euler)
    print(f"é‡‡é›†ç¬¬{count}ç»„ï¼Œæœºæ¢°è‡‚pose: {pose}")
    
    
    with open(f"{save_path}poses.txt", "a+") as f:
        pose_str = ",".join([str(i) for i in pose])
        f.write(f"{pose_str}\n")
        
    cv2.imwrite(f"{save_path}{count}.jpg", color_image)

def detect_aruco_pose(cam, color_image):
    # æ£€æµ‹æ£‹ç›˜æ ¼,æ£‹ç›˜æ˜¯11x8ï¼Œæ–¹æ ¼è¾¹é•¿15mm
    squaresX, squaresY, squareLength = 11, 8, 0.02
    criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 30, 0.001)
    objp = np.zeros((squaresX * squaresY, 3), np.float32)
    objp[:, :2] = np.mgrid[0:squaresX, 0:squaresY].T.reshape(-1, 2)
    objp = squareLength * objp
    
    gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)
    ret, corners = cv2.findChessboardCorners(gray, (squaresX, squaresY), None)
    if ret:
        corners2 = cv2.cornerSubPix(gray, corners, (5, 5), (-1, -1), criteria)
        board_rvec, board_tvec = cv2.solvePnP(objp, corners2, np.eye(3), np.zeros(5))[1:3]
        print("æ ‡å®šæ¿æ£€æµ‹æˆåŠŸï¼Œå·²ä¿å­˜æ•°æ®ã€‚")
        return board_rvec, board_tvec
    else:
        print("æœªæ£€æµ‹åˆ°æ ‡å®šæ¿ï¼Œè¯·è°ƒæ•´åé‡è¯•ã€‚")
        return None, None

def hand_eye_calibrate(arm_poses, all_board_rvecs, all_board_tvecs):
    """
    æ‰‹çœ¼æ ‡å®šï¼Œä½¿ç”¨å¤šç§ç®—æ³•å¹¶é€‰æ‹©æœ€ä¼˜ç»“æœ
    """
    R_arm = [T[:3, :3] for T in arm_poses]
    t_arm = [T[:3, 3].reshape(3, 1) for T in arm_poses]  # ç¡®ä¿æ˜¯ (3,1) å½¢çŠ¶
    R_board = all_board_rvecs
    t_board = all_board_tvecs
    
    methods = {
        "Tsai-Lenz": cv2.CALIB_HAND_EYE_TSAI,
        "Horaud": cv2.CALIB_HAND_EYE_HORAUD,
        "Andreff": cv2.CALIB_HAND_EYE_ANDREFF,
        "Daniilidis": cv2.CALIB_HAND_EYE_DANIILIDIS
    }
    
    results = {}
    print("å¼€å§‹æ‰‹çœ¼æ ‡å®š...")
    
    for method_name, method_flag in methods.items():
        try:
            print(f"  æµ‹è¯•æ–¹æ³•ï¼š{method_name}")
            R, t = cv2.calibrateHandEye(R_arm, t_arm, R_board, t_board, method_flag)
            
            if R is None or t is None:
                print(f"    âŒ {method_name} æ ‡å®šå¤±è´¥")
                continue
            
            # æ„å»ºç›¸æœºåˆ°æœ«ç«¯çš„é½æ¬¡å˜æ¢çŸ©é˜µ
            M_cam2end = np.eye(4)
            M_cam2end[:3, :3] = R
            M_cam2end[:3, 3] = t.reshape(3)
            
            # è®¡ç®—æ ‡å®šæ¿åœ¨åŸºåº§ç³»ä¸‹çš„ä½ç½®ä¸€è‡´æ€§ï¼ˆè¯„ä¼°æ ‡å®šè´¨é‡ï¼‰
            board_positions = []
            for sub_R_arm, sub_t_arm, sub_rvec, sub_tvec in zip(R_arm, t_arm, R_board, t_board):
                # æœ«ç«¯åˆ°åŸºåº§
                M_end2base = np.eye(4)
                M_end2base[:3, :3] = sub_R_arm
                M_end2base[:3, 3] = sub_t_arm.reshape(3)
                
                # æ ‡å®šæ¿åˆ°ç›¸æœº
                R_board2cam, _ = cv2.Rodrigues(sub_rvec)
                M_board2cam = np.eye(4)
                M_board2cam[:3, :3] = R_board2cam
                M_board2cam[:3, 3] = sub_tvec.reshape(3)
                
                # æ ‡å®šæ¿åˆ°åŸºåº§
                M_board2base = M_end2base @ M_cam2end @ M_board2cam
                board_positions.append(M_board2base[:3, 3])
            
            # è®¡ç®—ä½ç½®æ ‡å‡†å·®
            board_positions = np.array(board_positions)
            mean_pos = np.mean(board_positions, axis=0)
            std_xyz = np.std(board_positions, axis=0)
            rms_error = np.sqrt(np.mean(np.sum((board_positions - mean_pos)**2, axis=1)))
            
            results[method_name] = {
                'R': R,
                't': t,
                'M_cam2end': M_cam2end,
                'std_xyz': std_xyz,
                'rms_error': rms_error,
                'mean_pos': mean_pos
            }
            
            print(f"    âœ… å®Œæˆï¼ŒRMSè¯¯å·®: {rms_error*1000:.2f} mm")
            
        except Exception as e:
            print(f"    âŒ {method_name} å‡ºé”™: {e}")
    
    if not results:
        print("âŒ æ‰€æœ‰æ ‡å®šæ–¹æ³•éƒ½å¤±è´¥äº†")
        return None, None
    
    # é€‰æ‹©RMSè¯¯å·®æœ€å°çš„ä½œä¸ºæœ€ä¼˜ç»“æœ
    best_method = min(results, key=lambda x: results[x]['rms_error'])
    best_result = results[best_method]
    
    print(f"\nğŸ¯ æœ€ä¼˜æ–¹æ³•: {best_method}")
    print(f"   RMSè¯¯å·®: {best_result['rms_error']*1000:.2f} mm")
    print(f"   ä½ç½®æ ‡å‡†å·® (XYZ): [{best_result['std_xyz'][0]*1000:.2f}, {best_result['std_xyz'][1]*1000:.2f}, {best_result['std_xyz'][2]*1000:.2f}] mm")
    
    # ä¿å­˜æœ€ä¼˜ç»“æœ
    np.savetxt("T_camera2end.txt", best_result['M_cam2end'])
    print("æœ€ä¼˜æ ‡å®šçŸ©é˜µå·²ä¿å­˜åˆ° T_camera2end.txt")
    
    return best_result['R'], best_result['t']

def main():
    count = 0 
    # åˆå§‹åŒ–ç›¸æœº
    cam = Camera(camera_model='D405')  # åˆå§‹åŒ–ç›¸æœº

    # åˆå§‹åŒ–æœºæ¢°è‡‚
    robot = DobotRobot("192.168.5.2", no_gripper=True)
    robot.r_inter.StartDrag()
    print("å·²è¿›å…¥æ‹–æ‹½æ¨¡å¼ï¼Œè¯·æ‰‹åŠ¨æ‹–åŠ¨æœºæ¢°è‡‚åˆ°ä¸åŒä½ç½®ï¼Œå¯¹å‡†æ ‡å®šæ¿ã€‚æ¯æ¬¡æŒ‰ç©ºæ ¼é‡‡é›†ä¸€ç»„æ•°æ®ï¼ŒESCé€€å‡ºã€‚")
    # breakpoint()

    arm_poses_text = []
    arm_poses = []
    all_board_rvecs = []
    all_board_tvecs = []
    T_camera2end = np.eye(4)

    # with open(f"{save_path}poses.txt", "r") as f:
    #     for line in f:
    #         arm_pose = line.strip().split(",")
    #         arm_pose = [float(i) for i in arm_pose]
    #         arm_poses_text.append(arm_pose)
    

    # for pose in arm_poses_text:
    #     T = np.eye(4)
    #     T[:3, :3] = R.from_euler('xyz', pose[3:6], degrees=False).as_matrix()
    #     T[:3, 3] = pose[:3]
    #     arm_poses.append(T)

    # image_path_dir = './collect_data/'
    # for image_name in os.listdir(image_path_dir):
    #     if image_name.endswith(".jpg"):
    #         image_path_full = os.path.join(image_path_dir, image_name)
    #         print(image_path_full)
    #         color_image = cv2.imread(image_path_full)
    #         board_rvec, board_tvec = detect_aruco_pose(cam, color_image)
    #         all_board_rvecs.append(board_rvec)
    #         all_board_tvecs.append(board_tvec)

    
    # hand_eye_calibrate(arm_poses, all_board_rvecs, all_board_tvecs)
    
    # return 0
    
    with open(f"{save_path}poses.txt", "w") as f:
        f.write("")  # æ¸…ç©ºæ–‡ä»¶å†…å®¹

    while True:
        color_image, depth_image = cam.get_frames()
        if color_image is None:
            continue
        cv2.imshow("drag_hand_eye", color_image)
        key = cv2.waitKey(1) & 0xFF

        if key == 32:  # ç©ºæ ¼é‡‡é›†
            T = robot.get_pose_matrix()  # è·å–4x4é½æ¬¡å˜æ¢çŸ©é˜µï¼Œä½ç½®å•ä½ä¸ºç±³
            board_rvec, board_tvec = detect_aruco_pose(cam, color_image)
            if board_rvec is not None and board_tvec is not None:
                all_board_rvecs.append(board_rvec)
                all_board_tvecs.append(board_tvec)
                arm_poses.append(T)  # ç›´æ¥ä¿å­˜4x4çŸ©é˜µ
                collect_data(T,color_image,count)
                count += 1
                if count >= 5:  # æœ€å°‘é‡‡é›†5ç»„æ•°æ®
                    hand_eye_calibrate(arm_poses, all_board_rvecs, all_board_tvecs)
            else:
                print("æœªæ£€æµ‹åˆ°æ ‡å®šæ¿ï¼Œæœªä¿å­˜æ•°æ®ã€‚è¯·è°ƒæ•´æœºæ¢°è‡‚ä½ç½®åé‡è¯•ã€‚")
                continue
        elif key == 27:  # ESCé€€å‡º
            break

    robot.r_inter.StopDrag()
    print("é‡‡é›†ç»“æŸ")
    
            
            
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
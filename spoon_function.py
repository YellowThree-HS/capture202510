import cv2
import numpy as np
import os
from lib.camera import Camera
from lib.mask2pose import mask2pose, draw_pose_axes
from ultralytics import YOLO
from lib.dobot import DobotRobot

def detect_spoon_pose(cam, conf_threshold=0.6, robot_matrix=None):
    color_image, depth_image = cam.get_frames()

    color_filename = f'spoon/color.png'
    depth_filename = f'spoon/depth.png'

    cv2.imwrite(color_filename, color_image)
    cv2.imwrite(depth_filename, depth_image)
    if len(depth_image.shape) == 3:
        depth_image = depth_image[:, :, 0]
    # RealSense D405çš„æ·±åº¦æ¯”ä¾‹æ˜¯0.0001
    depth_scale = 0.0001
    depth_image = depth_image.astype(np.float32) * depth_scale
    model_path = 'weights/best.pt'  # ä½¿ç”¨detect2.pyä¸­çš„æ¨¡å‹
    # 1. ç›®æ ‡æ£€æµ‹
    model = YOLO(model_path)
    results = model.predict(
        source=color_image,
        save=False,
        conf=conf_threshold,
        iou=0.7,
        show_labels=False,
        show_conf=False,
        verbose=False
    )

    result = results[0]
    num_detections = len(result.masks) 
    spoon_detected = False
    spoon_obj = None

    for i in range(num_detections):
        class_id = int(result.boxes.cls[i])
        class_name = result.names[class_id]
        
        # åªå¤„ç†spoonç±»åˆ«
        if class_name.lower() == 'spoon':
            mask = result.masks.data[i].cpu().numpy()  # è·å–æ©ç 
            confidence = float(result.boxes.conf[i])
            bbox = result.boxes.xyxy[i].cpu().numpy().tolist()  # [x1, y1, x2, y2]
            
            spoon_obj = {
                'class': class_name,
                'confidence': confidence,
                'bbox_xyxy': bbox,
                'mask': mask
            }
            spoon_detected = True
            break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªspoonå°±åœæ­¢

    intrinsics = cam.get_camera_matrix()

    # 2. ä½¿ç”¨mask2poseè¿›è¡Œä½å§¿ä¼°è®¡
    pose, T_object2cam = mask2pose(
        mask=spoon_obj['mask'],
        depth_image=depth_image,
        color_image=color_image,
        intrinsics=intrinsics,
        T_cam2base=None,
        object_class='spoon'
    )
    # 3. è½¬æ¢åˆ°æœºæ¢°è‡‚åŸºåæ ‡ç³»
    hand_eye_matrix = np.array([
            [ 0.01230037,  0.99763761,  0.06758625,  0.08419052],
            [-0.99992251,  0.01240196, -0.00108365,  0.00995925],
            [-0.00191929, -0.06756769,  0.99771285, -0.15882536],
            [ 0.0,         0.0,         0.0,         1.0        ]
        ])

    if robot_matrix is not None:
        robot_pose_matrix = robot_matrix
    else:
        robot_pose_matrix = np.eye(4)
    # å‹ºå­ä¸­å¿ƒçš„ä½å§¿çŸ©é˜µ
    pose_matrix = robot_pose_matrix @ hand_eye_matrix @ T_object2cam

    # æå–å‹ºå­é¢å¤–ä¿¡æ¯
    spoon_info = {}
    if len(pose) > 6:  # å¦‚æœæœ‰é¢å¤–ä¿¡æ¯ï¼ˆå‹ºå¤´ä¸­å¿ƒç­‰ï¼‰
        spoon_info = pose[6]  # ç¬¬7ä¸ªå…ƒç´ æ˜¯é¢å¤–ä¿¡æ¯
        pose = pose[:6]  # åªä¿ç•™å‰6ä¸ªå…ƒç´ ä½œä¸ºåŸºæœ¬ä½å§¿

    # 1. å‹ºå­æ•´ä½“ä¸­å¿ƒçš„ä½å§¿çŸ©é˜µï¼ˆç”¨äºæŠ“å–å‹ºå­çš„å‡ ä½•ä¸­å¿ƒï¼‰
    spoon_center_pose_matrix = pose_matrix

    # 2. å‹ºæŸ„ä¸­å¿ƒçš„ä½å§¿çŸ©é˜µï¼ˆç”¨äºæŠ“å–å‹ºæŸ„ï¼‰
    # ä½¿ç”¨ä¸å‹ºå­æ•´ä½“ä¸­å¿ƒç›¸åŒçš„æ—‹è½¬çŸ©é˜µï¼Œåªæ”¹å˜ä½ç½®
    spoon_handle_center = spoon_info['spoon_handle_center']
    spoon_handle_center_matrix = T_object2cam.copy()  # å¤åˆ¶æ•´ä½“ä½å§¿çŸ©é˜µ
    spoon_handle_center_matrix[:3, 3] = spoon_handle_center  # åªæ›´æ–°ä½ç½®
    spoon_handle_center_pose_matrix = robot_pose_matrix @ hand_eye_matrix @ spoon_handle_center_matrix

    # 3. å‹ºå¤´ä¸­å¿ƒçš„ä½å§¿çŸ©é˜µï¼ˆç”¨äºæŠ“å–å‹ºå¤´ï¼‰
    # ä½¿ç”¨ä¸å‹ºå­æ•´ä½“ä¸­å¿ƒç›¸åŒçš„æ—‹è½¬çŸ©é˜µï¼Œåªæ”¹å˜ä½ç½®
    spoon_head_center = spoon_info['spoon_head_center']
    spoon_head_center_matrix = T_object2cam.copy()  # å¤åˆ¶æ•´ä½“ä½å§¿çŸ©é˜µ
    spoon_head_center_matrix[:3, 3] = spoon_head_center  # åªæ›´æ–°ä½ç½®
    spoon_head_center_pose_matrix = robot_pose_matrix @ hand_eye_matrix @ spoon_head_center_matrix

    # å¯è§†åŒ–ä½å§¿ã€å‹ºæŸ„ä¸­å¿ƒå’Œå‹ºå¤´ä¸­å¿ƒ
    try:
        draw_pose_axes(color_image, intrinsics, T_object2cam)
        
        visualization_added = False
        
        # æ·»åŠ å‹ºæŸ„ä¸­å¿ƒçš„æ©™è‰²ç‚¹æ ‡è®°
        if spoon_info and 'spoon_handle_center' in spoon_info:
            handle_center_cam = spoon_info['spoon_handle_center']  # ç›¸æœºåæ ‡ç³»ä¸‹çš„å‹ºæŸ„ä¸­å¿ƒ
            
            # å°†3Dç‚¹æŠ•å½±åˆ°2Då›¾åƒåæ ‡
            handle_center_3d = np.array([handle_center_cam[0], handle_center_cam[1], handle_center_cam[2]])
            handle_center_2d, _ = cv2.projectPoints(
                handle_center_3d.reshape(-1, 1, 3),
                np.zeros(3), np.zeros(3),
                intrinsics[:3, :3], np.zeros(4)
            )
            handle_center_2d = handle_center_2d[0, 0].astype(int)
            
            # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ©™è‰²åœ†ç‚¹æ ‡è®°å‹ºæŸ„ä¸­å¿ƒ
            cv2.circle(color_image, tuple(handle_center_2d), 8, (0, 165, 255), -1)  # æ©™è‰²å®å¿ƒåœ†
            cv2.circle(color_image, tuple(handle_center_2d), 12, (0, 100, 200), 2)  # æ©™è‰²è¾¹æ¡†
            
            # æ·»åŠ æ–‡å­—æ ‡ç­¾
            cv2.putText(color_image, 'Handle', 
                       (handle_center_2d[0] + 15, handle_center_2d[1] - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 165, 255), 2)
            
            print(f"  å‹ºæŸ„ä¸­å¿ƒ2Dåæ ‡: [{handle_center_2d[0]}, {handle_center_2d[1]}]")
            visualization_added = True
        
        # æ·»åŠ å‹ºå¤´ä¸­å¿ƒçš„è“è‰²ç‚¹æ ‡è®°
        if spoon_info and 'spoon_head_center' in spoon_info:
            head_center_cam = spoon_info['spoon_head_center']  # ç›¸æœºåæ ‡ç³»ä¸‹çš„å‹ºå¤´ä¸­å¿ƒ
            
            # å°†3Dç‚¹æŠ•å½±åˆ°2Då›¾åƒåæ ‡
            head_center_3d = np.array([head_center_cam[0], head_center_cam[1], head_center_cam[2]])
            head_center_2d, _ = cv2.projectPoints(
                head_center_3d.reshape(-1, 1, 3),
                np.zeros(3), np.zeros(3),
                intrinsics[:3, :3], np.zeros(4)
            )
            head_center_2d = head_center_2d[0, 0].astype(int)
            
            # åœ¨å›¾åƒä¸Šç»˜åˆ¶è“è‰²åœ†ç‚¹æ ‡è®°å‹ºå¤´ä¸­å¿ƒ
            cv2.circle(color_image, tuple(head_center_2d), 8, (255, 100, 0), -1)  # è“è‰²å®å¿ƒåœ†
            cv2.circle(color_image, tuple(head_center_2d), 12, (200, 50, 0), 2)   # è“è‰²è¾¹æ¡†
            
            # æ·»åŠ æ–‡å­—æ ‡ç­¾
            cv2.putText(color_image, 'Head', 
                       (head_center_2d[0] + 15, head_center_2d[1] - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 100, 0), 2)
            
            print(f"  å‹ºå¤´ä¸­å¿ƒ2Dåæ ‡: [{head_center_2d[0]}, {head_center_2d[1]}]")
            visualization_added = True
        
        # å¦‚æœæ·»åŠ äº†å¯è§†åŒ–ï¼Œä¿å­˜å›¾åƒ
        if visualization_added:
            result_filename = f'spoon/spoon_with_both_centers.png'
            cv2.imwrite(result_filename, color_image)
            print(f"  å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {result_filename}")
    except Exception as e:
        print(f"ä½å§¿å¯è§†åŒ–å¤±è´¥: {e}")

    return {
        'spoon_center_pose_matrix': spoon_center_pose_matrix,      # å‹ºå­æ•´ä½“ä¸­å¿ƒä½å§¿çŸ©é˜µ
        'spoon_handle_pose_matrix': spoon_handle_center_pose_matrix,  # å‹ºæŸ„ä¸­å¿ƒä½å§¿çŸ©é˜µ
        'spoon_head_pose_matrix': spoon_head_center_pose_matrix,    # å‹ºå¤´ä¸­å¿ƒä½å§¿çŸ©é˜µ
    }

def main():
    """
    ä¸»å‡½æ•° - åˆå§‹åŒ–ç›¸æœºå¹¶è¿è¡Œæ£€æµ‹
    """
    print("ğŸš€ å‹ºå­æ£€æµ‹å’Œä½å§¿ä¼°è®¡ç¨‹åº")

    cam = Camera(camera_model='D405')

    robot=DobotRobot(robot_ip='192.168.5.2',no_gripper=True)
    robot_matrix = robot.get_pose_matrix()
    result = detect_spoon_pose(cam, conf_threshold=0.5, robot_matrix=robot_matrix)
    print(result)
    cam.release()


if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    main()
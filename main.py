"""
å®æ—¶D435ç›¸æœºæ£€æµ‹ç¨‹åº - æ¯å­ä½å§¿ä¼°è®¡
æŒ‰ ç©ºæ ¼é”® è§¦å‘æ£€æµ‹å’Œä½å§¿ä¼°è®¡
æŒ‰ 'q' é€€å‡ºç¨‹åº
æŒ‰ 'v' å¯è§†åŒ–ä½å§¿ï¼ˆéœ€è¦Open3Dï¼‰
"""

import cv2
import os
import time
import numpy as np
from datetime import datetime
from lib.camera import Camera
from lib.yolo_and_sam import YOLOSegmentator
from lib.mask2pose import mask2pose, visualize_result


def main():
    # --- é…ç½® ---
    # ä½ æƒ³è¦æ£€æµ‹çš„ç‰©ä½“ç±»åˆ«ï¼ˆå¯ä»¥æ£€æµ‹å¤šä¸ªï¼‰
    categories_to_find = ["cup", "spoon"]
    
    # ä¸´æ—¶å›¾ç‰‡ä¿å­˜ç›®å½•
    temp_dir = "./temp"
    os.makedirs(temp_dir, exist_ok=True)
    
    # ç›¸æœºåˆ°åŸºåæ ‡ç³»çš„å˜æ¢ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    # å¦‚æœæ²¡æœ‰ï¼Œè®¾ä¸ºNoneï¼Œå°†åœ¨ç›¸æœºåæ ‡ç³»ä¸­è®¡ç®—ä½å§¿
    T_cam2base = None  # å¯ä»¥è®¾ç½®ä¸ºä½ çš„å®é™…å˜æ¢çŸ©é˜µ
    
    print("=" * 60)
    print("å®æ—¶D435ç›¸æœºæ£€æµ‹ç¨‹åº - å¤šç‰©ä½“ä½å§¿ä¼°è®¡")
    print("=" * 60)
    print("æ£€æµ‹ç±»åˆ«: " + ", ".join(categories_to_find))
    print("ç­–ç•¥: æ¯ä¸ªç±»åˆ«åªæ£€æµ‹ç½®ä¿¡åº¦æœ€é«˜çš„ç‰©ä½“")
    print("=" * 60)
    print("æ§åˆ¶è¯´æ˜:")
    print("  ç©ºæ ¼é”® - è§¦å‘æ£€æµ‹å’Œä½å§¿ä¼°è®¡")
    print("  'v' é”® - 3Då¯è§†åŒ–æœ€åä¸€æ¬¡æ£€æµ‹ç»“æœ")
    print("  'q' é”® - é€€å‡ºç¨‹åº")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç›¸æœº
    try:
        cam = Camera(camera_model='D435')
    except Exception as e:
        print(f"ç›¸æœºåˆå§‹åŒ–å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿D435ç›¸æœºå·²æ­£ç¡®è¿æ¥")
        return
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨ï¼ˆæŒ‰ç©ºæ ¼åæ‰åŠ è½½ï¼Œé¿å…å¯åŠ¨å¤ªæ…¢ï¼‰
    segmentator = None
    
    # ä¿å­˜æœ€åä¸€æ¬¡æ£€æµ‹çš„æ•°æ®ï¼Œç”¨äºå¯è§†åŒ–
    last_detection_data = None
    
    try:
        print("\nå¼€å§‹å®æ—¶é¢„è§ˆ...")
        
        while True:
            # è·å–ç›¸æœºç”»é¢
            color_image, depth_image = cam.get_frames()
            
            if color_image is None:
                print("æ— æ³•è·å–ç›¸æœºç”»é¢")
                break
            
            # è½¬æ¢æ·±åº¦å›¾å•ä½ï¼šä»æ¯«ç±³è½¬æ¢ä¸ºç±³
            if depth_image is not None:
                depth_image_meters = depth_image.astype(float) * cam.depth_scale
            else:
                depth_image_meters = None
            
            # åœ¨ç”»é¢ä¸Šæ˜¾ç¤ºæç¤ºä¿¡æ¯
            display_image = color_image.copy()
            cv2.putText(display_image, "SPACE: Detect | V: Visualize | Q: Quit", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # æ˜¾ç¤ºç”»é¢
            cv2.imshow("D435 Camera - Real-time", display_image)
            
            # æ£€æµ‹æŒ‰é”®
            key = cv2.waitKey(1) & 0xFF
            
            # æŒ‰ 'q' é€€å‡º
            if key == ord('q'):
                print("\né€€å‡ºç¨‹åº...")
                break
            
            # æŒ‰ 'v' å¯è§†åŒ–
            elif key == ord('v'):
                if last_detection_data is not None:
                    print("\næ­£åœ¨æ‰“å¼€3Då¯è§†åŒ–çª—å£...")
                    # æ£€æŸ¥æ˜¯å•ä¸ªä½å§¿è¿˜æ˜¯å¤šä¸ªä½å§¿
                    if 'pose' in last_detection_data:
                        # å•ä¸ªç‰©ä½“ï¼ˆå‘åå…¼å®¹ï¼‰
                        visualize_result(
                            last_detection_data['color'],
                            last_detection_data['depth'],
                            T_cam2base,
                            cam.get_camera_matrix(),
                            last_detection_data['pose']
                        )
                    elif 'poses' in last_detection_data:
                        # å¤šä¸ªç‰©ä½“
                        from lib.mask2pose import visualize_multi_objects
                        visualize_multi_objects(
                            last_detection_data['color'],
                            last_detection_data['depth'],
                            T_cam2base,
                            cam.get_camera_matrix(),
                            last_detection_data['poses']
                        )
                else:
                    print("\nâš ï¸ å°šæœªè¿›è¡Œæ£€æµ‹ï¼Œè¯·å…ˆæŒ‰ç©ºæ ¼é”®è¿›è¡Œæ£€æµ‹")
            
            # æŒ‰ç©ºæ ¼é”®è§¦å‘æ£€æµ‹
            elif key == ord(' '):
                print("\n" + "=" * 60)
                print("è§¦å‘å¤šç‰©ä½“æ£€æµ‹...")
                
                # å»¶è¿ŸåŠ è½½æ£€æµ‹å™¨ï¼ˆèŠ‚çœå¯åŠ¨æ—¶é—´ï¼‰
                if segmentator is None:
                    print("é¦–æ¬¡æ£€æµ‹ï¼Œæ­£åœ¨åŠ è½½æ¨¡å‹...")
                    segmentator = YOLOSegmentator()
                
                # ä¿å­˜å½“å‰å¸§åˆ°ä¸´æ—¶æ–‡ä»¶
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                temp_image_path = os.path.join(temp_dir, f"frame_{timestamp}.jpg")
                cv2.imwrite(temp_image_path, color_image)
                
                # æ‰§è¡Œæ£€æµ‹å’Œåˆ†å‰²ï¼ˆæ‰€æœ‰ç‰©ä½“ï¼‰
                start_time = time.time()
                result = segmentator.detect_and_segment_all(
                    image=temp_image_path,
                    categories=categories_to_find
                )
                end_time = time.time()
                
                # æ˜¾ç¤ºç»“æœ
                if result['success']:
                    num_objects = len(result['objects'])
                    print(f"\nâœ“ æ£€æµ‹æˆåŠŸ! å…±æ£€æµ‹åˆ° {num_objects} ä¸ªç‰©ä½“ (è€—æ—¶: {end_time - start_time:.2f}s)")
                    print(f"  æ£€æµ‹ç»“æœ: {result['detection_path']}")
                    
                    # æ˜¾ç¤ºæ£€æµ‹ç»“æœå›¾åƒ
                    det_img = cv2.imread(result['detection_path'])
                    if det_img is not None:
                        cv2.imshow("Detection Result", det_img)
                    
                    # ä¸ºæ¯ä¸ªç‰©ä½“è®¡ç®—ä½å§¿
                    if depth_image_meters is not None:
                        all_poses = []
                        
                        print("\n" + "=" * 60)
                        print("å¼€å§‹ä½å§¿ä¼°è®¡...")
                        print("=" * 60)
                        
                        for idx, obj in enumerate(result['objects']):
                            print(f"\nğŸ” ç‰©ä½“ {idx+1}/{num_objects}: {obj['class']}")
                            print(f"   ç½®ä¿¡åº¦: {obj['confidence']:.2f}")
                            print(f"   è¾¹ç•Œæ¡†: {obj['bbox_xyxy']}")
                            
                            # å¦‚æœæœ‰æ©ç ï¼Œè®¡ç®—ä½å§¿
                            if obj['mask'] is not None:
                                pose_start = time.time()
                                pose, T = mask2pose(
                                    mask=obj['mask'],
                                    depth_image=depth_image_meters,
                                    color_image=color_image,
                                    intrinsics=cam.get_camera_matrix(),
                                    T_cam2base=T_cam2base,
                                    object_class=obj['class']  # ä¼ å…¥ç‰©ä½“ç±»åˆ«
                                )
                                pose_end = time.time()
                                
                                if pose is not None:
                                    print(f"   ä½å§¿ä¼°è®¡è€—æ—¶: {pose_end - pose_start:.2f}s")
                                    print(f"   ğŸ“ ä½ç½® (x, y, z): [{pose[0]:.3f}, {pose[1]:.3f}, {pose[2]:.3f}] ç±³")
                                    print(f"   ğŸ“ å§¿æ€ (roll, pitch, yaw): [{pose[3]:.1f}Â°, {pose[4]:.1f}Â°, {pose[5]:.1f}Â°]")
                                    
                                    # æ£€æŸ¥æ˜¯å¦æœ‰å‹ºå­çš„é¢å¤–ä¿¡æ¯
                                    extra_info = None
                                    if isinstance(pose, list) and len(pose) > 6 and isinstance(pose[6], dict):
                                        extra_info = pose[6]
                                        if 'spoon_head_center' in extra_info:
                                            head_center = extra_info['spoon_head_center']
                                            head_radius = extra_info['spoon_head_radius']
                                            handle_pose = extra_info['handle_pose']
                                            print(f"   ğŸ¥„ å‹ºå¤´ä¸­å¿ƒä½ç½®: [{head_center[0]:.3f}, {head_center[1]:.3f}, {head_center[2]:.3f}] ç±³")
                                            print(f"   ğŸ¥„ å‹ºå¤´åŠå¾„: {head_radius:.3f}m ({head_radius*100:.1f}cm)")
                                            print(f"   ğŸ¥„ å‹ºæŸ„å§¿æ€: [roll={handle_pose[0]:.1f}Â°, pitch={handle_pose[1]:.1f}Â°, yaw={handle_pose[2]:.1f}Â°]")
                                    
                                    all_poses.append({
                                        'class': obj['class'],
                                        'pose': pose,
                                        'confidence': obj['confidence'],
                                        'extra_info': extra_info
                                    })
                                else:
                                    print(f"   âŒ ä½å§¿ä¼°è®¡å¤±è´¥")
                            else:
                                print(f"   âš ï¸ æœªè·å–åˆ°æ©ç ")
                        
                        # ä¿å­˜æœ€åä¸€æ¬¡æ£€æµ‹æ•°æ®ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
                        if len(all_poses) > 0:
                            last_detection_data = {
                                'color': color_image.copy(),
                                'depth': depth_image_meters.copy(),
                                'poses': all_poses  # ä¿å­˜æ‰€æœ‰ä½å§¿
                            }
                            
                            print("\n" + "=" * 60)
                            print(f"âœ… æˆåŠŸä¼°è®¡äº† {len(all_poses)} ä¸ªç‰©ä½“çš„ä½å§¿")
                            print("=" * 60)
                            
                            # æ‰“å°æ±‡æ€»ä¿¡æ¯
                            print("\nğŸ“Š ä½å§¿æ±‡æ€»:")
                            for i, pose_info in enumerate(all_poses):
                                pose = pose_info['pose']
                                print(f"\n  {i+1}. {pose_info['class']} (ç½®ä¿¡åº¦: {pose_info['confidence']:.2f})")
                                print(f"     ä½ç½®: [{pose[0]:.3f}, {pose[1]:.3f}, {pose[2]:.3f}] ç±³")
                                print(f"     å§¿æ€: [{pose[3]:.1f}Â°, {pose[4]:.1f}Â°, {pose[5]:.1f}Â°]")
                                
                                # å¦‚æœæœ‰é¢å¤–ä¿¡æ¯ï¼ˆå¦‚å‹ºå¤´ä¸­å¿ƒå’Œå‹ºæŸ„å§¿æ€ï¼‰ï¼Œä¹Ÿæ˜¾ç¤º
                                if 'extra_info' in pose_info and pose_info['extra_info']:
                                    extra = pose_info['extra_info']
                                    if 'spoon_head_center' in extra:
                                        head_center = extra['spoon_head_center']
                                        head_radius = extra['spoon_head_radius']
                                        handle_pose = extra['handle_pose']
                                        print(f"     å‹ºå¤´ä¸­å¿ƒä½ç½®: [{head_center[0]:.3f}, {head_center[1]:.3f}, {head_center[2]:.3f}] ç±³")
                                        print(f"     å‹ºå¤´åŠå¾„: {head_radius*100:.1f}cm")
                                        print(f"     å‹ºæŸ„å§¿æ€: [roll={handle_pose[0]:.1f}Â°, pitch={handle_pose[1]:.1f}Â°, yaw={handle_pose[2]:.1f}Â°]")
                            
                            print("\nğŸ’¡ æç¤º: æŒ‰ 'v' é”®å¯è¿›è¡Œ3Då¯è§†åŒ–")
                        else:
                            print("\nâš ï¸ æ²¡æœ‰æˆåŠŸä¼°è®¡ä»»ä½•ç‰©ä½“çš„ä½å§¿")
                    else:
                        print("\nâš ï¸ æœªè·å–åˆ°æ·±åº¦å›¾ï¼Œæ— æ³•è¿›è¡Œä½å§¿ä¼°è®¡")
                    
                else:
                    print(f"\nâœ— æ£€æµ‹å¤±è´¥")
                
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_image_path):
                    os.remove(temp_image_path)
                
                print("=" * 60)
    
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­ç¨‹åº...")
    
    except Exception as e:
        print(f"\nå‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æ¸…ç†èµ„æº
        cam.release()
        cv2.destroyAllWindows()
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if os.path.exists(temp_dir) and len(os.listdir(temp_dir)) == 0:
            os.rmdir(temp_dir)
        
        print("\nèµ„æºå·²é‡Šæ”¾ï¼Œç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()

# 位姿估计 - 5步速览

## 🎯 从掩码到位姿的5个步骤

---

## 步骤1️⃣: 掩码过滤

```
输入: 掩码 (480×640)
┌─────────────────┐
│ 0 0 0 1 1 1 0 0 │   0 = 背景
│ 0 0 1 1 1 1 1 0 │   1 = 物体
│ 0 1 1 1 1 1 1 0 │
│ 0 0 1 1 1 1 0 0 │
└─────────────────┘

作用: 只保留物体区域的深度和颜色数据

代码:
depth_masked = depth_image * mask
color_masked = color_image * mask[:,:,np.newaxis]
```

---

## 步骤2️⃣: 点云生成

```
2D像素 + 深度 → 3D点云

像素(320,240) + 深度0.5m → 点(0.00, 0.00, 0.50)
像素(325,240) + 深度0.5m → 点(0.01, 0.00, 0.50)
像素(320,245) + 深度0.5m → 点(0.00, 0.01, 0.50)
...
约5000-20000个点

公式:
x = (u - cx) * z / fx
y = (v - cy) * z / fy
z = depth_value

结果: 3D点云
   •  •  •
  •  •  •  •
 •  •  •  •  •
  •  •  •  •
   •  •  •
```

---

## 步骤3️⃣: 平面检测 (RANSAC)

```
目标: 找到物体的顶面

RANSAC算法:
1. 随机选3个点 → 拟合平面
2. 计算所有点到平面的距离
3. 统计距离<5mm的点数（内点）
4. 重复1000次
5. 选内点最多的平面

侧视图:
    ═══════════  ← 顶面（被检测到）
    ║       ║
    ║  杯子  ║
    ║       ║
    ╚═══════╝

平面方程: ax + by + cz + d = 0
结果: [a, b, c, d] = [0.01, -0.02, 0.999, -0.567]
      法向量: (0.01, -0.02, 0.999) ≈ (0, 0, 1) 朝上✓
```

---

## 步骤4️⃣: 特征提取

```
从顶面提取关键信息:

A. 中心位置
   顶面所有点的平均值
   
   俯视图:
   × × × × ×
   ×       ×
   ×   ⊕   ×  ← 中心
   ×       ×
   × × × × ×
   
   center = mean(所有顶面点)
   结果: [0.123, -0.045, 0.567] 米

B. 法向量
   垂直于顶面的方向
   
        ↑ normal
        │
   ═════════
   ║     ║
   
   结果: [0.012, -0.034, 0.999]
   解释: 几乎竖直向上（杯子未倾斜）

C. 半径（可选）
   顶面点到中心的平均距离
   结果: 0.035m (3.5cm)
```

---

## 步骤5️⃣: 位姿计算

```
目标: 建立物体的完整坐标系

A. 构建坐标系 (3个轴)

   Z轴 = 法向量方向
   X轴 = Z × [0,1,0] (叉乘得到)
   Y轴 = Z × X       (叉乘得到)

   可视化:
         Z↑ (蓝)
         │
    ═════════
    ║     ║
Y ←─║  ⊕  ║
(绿) ║     ║
    ╚═════╝
   ／
  X (红)

B. 构建变换矩阵 T (4×4)

   T = [ X轴  Y轴  Z轴  中心 ]
       [  0    0    0    1   ]

C. 转换为位姿

   位置: [x, y, z] = 中心坐标
   姿态: [roll, pitch, yaw] = 从旋转矩阵提取

最终输出:
pose = [x, y, z, roll, pitch, yaw]
     = [0.123, -0.045, 0.567, 2.3°, -1.5°, 45.6°]
```

---

## 📊 数据流总结

```
掩码(480×640)
    ↓
深度图(480×640) + 彩色图(480×640×3)
    ↓ [步骤1: 过滤]
被遮罩的深度 + 颜色
    ↓ [步骤2: 投影]
点云(~10000个点)
    ↓ [步骤3: RANSAC]
顶面平面 + 内点索引
    ↓ [步骤4: 计算]
中心[x,y,z] + 法向量[nx,ny,nz]
    ↓ [步骤5: 构建]
变换矩阵T(4×4)
    ↓ [转换]
位姿 [x, y, z, roll, pitch, yaw]
```

---

## ⏱️ 典型耗时

```
步骤1: 掩码过滤    < 1ms   ⚡
步骤2: 点云生成    10-20ms 
步骤3: 平面检测    20-30ms 
步骤4: 特征提取    5-10ms  
步骤5: 位姿计算    < 1ms   ⚡

总计: ~40-60ms (单个物体)
```

---

## 🎓 关键概念

### 1. 针孔相机模型
像素坐标通过焦距和深度转换为3D坐标

### 2. RANSAC
鲁棒地从噪声数据中拟合平面

### 3. 叉乘
生成互相垂直的坐标轴

### 4. 齐次变换
用4×4矩阵表示位置+姿态

---

## ✅ 成功案例

```
物体: 白色陶瓷杯
距离: 0.5米
姿态: 竖直

输出:
✅ 杯子位姿估计成功
   位置: [0.000, 0.000, 0.500] 米
   姿态: [0.0°, 0.0°, 0.0°]
   
解释:
- 在相机正前方50cm
- 完全竖直
- 无旋转
```

---

## ⚠️ 常见问题

### Q: 为什么需要平面？
A: 平面能提供姿态信息（物体是否倾斜）

### Q: 勺子也用这个方法吗？
A: 是的，但勺子没有明显平面，所以结果可能不太准确

### Q: 如何提高精度？
A: 
1. 改善光照
2. 减少遮挡
3. 选择合适距离(0.3-2m)
4. 使用质感好的物体（非反光）

---

## 📝 代码位置

```python
# 主函数
lib/mask2pose.py: mask2pose()

# 核心步骤
lib/mask2pose.py:
  ├─ create_point_cloud()        # 步骤2
  ├─ extract_cup_features()      # 步骤3+4
  ├─ calculate_cup_pose()        # 步骤5
  └─ transform_matrix_to_pos_euler()  # 转换

# 调用位置
main.py: 第166行
```

---

**完整技术细节**: 查看 `POSE_ESTIMATION_EXPLAINED.md`

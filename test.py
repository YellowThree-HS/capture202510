

import cv2
import os
import time
import numpy as np
from datetime import datetime
from lib.camera import Camera
from lib.yolo_and_sam import YOLOSegmentator
from lib.mask2pose import mask2pose, visualize_result


def main():

    cam = Camera(camera_model='D435')  # åˆå§‹åŒ–ç›¸æœº
    color_image = cam.get_color_image()
    print(type(color_image))
    depth_image = cam.get_depth_image()
    depth_image_meters = depth_image.astype(np.float32) / 1000.0  # è½¬æ¢ä¸ºç±³

    # color_image = 'images/cup1.jpg'
    T_cam2base = np.eye(4)  # å‡è®¾ç›¸æœºä½å§¿å·²çŸ¥ï¼Œè¿™é‡Œä½¿ç”¨å•ä½çŸ©é˜µä½œä¸ºç¤ºä¾‹
    

    categories_to_find = ['spoon','cup']
    segmentator = YOLOSegmentator()
    # result 
    result = segmentator.detect_and_segment_all(
        image=color_image,
        categories=categories_to_find,
        save_result=True
    )
    print("Detection and segmentation result:", result)



    # result[''objects']æ˜¯ä¸€ä¸ªå­—å…¸çš„listï¼Œæ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€ä¸ªç‰©ä½“åŒ…å«ç±»åˆ«ã€ç½®ä¿¡åº¦ã€è¾¹ç•Œæ¡†å’Œæ©ç 
    for idx, obj in enumerate(result['objects']):
        print(f"ç½®ä¿¡åº¦: {obj['confidence']:.2f}")
        print(f"è¾¹ç•Œæ¡†: {obj['bbox_xyxy']}")
        
        # å¦‚æœæœ‰æ©ç ï¼Œè®¡ç®—ä½å§¿
        if obj['mask'] is not None:

            pose, T = mask2pose(
                mask=obj['mask'],
                depth_image=depth_image_meters,
                color_image=color_image,
                intrinsics=cam.get_camera_matrix(),
                T_cam2base=T_cam2base,
                object_class=obj['class']  # ä¼ å…¥ç‰©ä½“ç±»åˆ«
            )
            
            if pose is not None:
                print(f"   ğŸ“ ä½ç½® (x, y, z): [{pose[0]:.3f}, {pose[1]:.3f}, {pose[2]:.3f}] ç±³")
                print(f"   ğŸ“ å§¿æ€ (roll, pitch, yaw): [{pose[3]:.1f}Â°, {pose[4]:.1f}Â°, {pose[5]:.1f}Â°]")
            else:
                print(f"   âŒ ä½å§¿ä¼°è®¡å¤±è´¥")
        else:
            print(f"   âš ï¸ æœªè·å–åˆ°æ©ç ")




if __name__ == "__main__":
    main()

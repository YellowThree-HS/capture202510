"""
æ¯å­æ£€æµ‹å’Œä½å§¿ä¼°è®¡å‡½æ•°
åŠŸèƒ½ï¼šä¼ å…¥RGBå›¾å’Œæ·±åº¦å›¾ï¼Œè¯†åˆ«å›¾ç‰‡æ£€æµ‹æ¯å­å¹¶åˆ†å‰²ï¼Œæœ€åè¿”å›ä½å§¿
åŒ…å«æ‰‹çœ¼æ ‡å®šçŸ©é˜µ
"""

import cv2
import numpy as np
import os
from lib.camera import Camera
from lib.yolo_and_sam import YOLOSegmentator
from lib.mask2pose import mask2pose, draw_pose_axes


def detect_cup_pose(rgb_image, depth_image, camera_model='D405', conf_threshold=0.1, robot_matrix=None):
    """
    æ£€æµ‹æ¯å­å¹¶è¿”å›ä½å§¿
    
    å‚æ•°:
        rgb_image: RGBå›¾åƒ (numpy.ndarray) æˆ–å›¾åƒè·¯å¾„ (str)
        depth_image: æ·±åº¦å›¾åƒ (numpy.ndarray) æˆ–å›¾åƒè·¯å¾„ (str)
        camera_model: ç›¸æœºå‹å·ï¼Œé»˜è®¤'D405'
        conf_threshold: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé»˜è®¤0.1
    
    è¿”å›:
        dict: {
            'success': bool,  # æ˜¯å¦æˆåŠŸæ£€æµ‹åˆ°æ¯å­
            'pose': [x, y, z, roll, pitch, yaw] or None,  # æ¯å­ä½å§¿ (ç±³, åº¦)
            'pose_matrix': np.ndarray or None,  # 4x4ä½å§¿å˜æ¢çŸ©é˜µ
            'detection_info': dict or None,  # æ£€æµ‹ä¿¡æ¯
            'error_message': str or None  # é”™è¯¯ä¿¡æ¯
        }
    """
    try:
        # 1. åˆå§‹åŒ–ç›¸æœºå¯¹è±¡ï¼ˆç”¨äºè·å–å†…å‚ï¼‰
        cam = Camera(camera_model=camera_model)
        
        # 2. å¤„ç†è¾“å…¥å›¾åƒ
        if isinstance(rgb_image, str):
            color_image = cv2.imread(rgb_image)
            if color_image is None:
                return {
                    'success': False,
                    'pose': None,
                    'pose_matrix': None,
                    'detection_info': None,
                    'error_message': f"æ— æ³•è¯»å–RGBå›¾åƒ: {rgb_image}"
                }
        else:
            color_image = rgb_image.copy()
        
        if isinstance(depth_image, str):
            depth_image_array = cv2.imread(depth_image, cv2.IMREAD_UNCHANGED)
            if depth_image_array is None:
                return {
                    'success': False,
                    'pose': None,
                    'pose_matrix': None,
                    'detection_info': None,
                    'error_message': f"æ— æ³•è¯»å–æ·±åº¦å›¾åƒ: {depth_image}"
                }
        else:
            depth_image_array = depth_image.copy()
        
        # 3. å¤„ç†æ·±åº¦å›¾åƒæ ¼å¼
        if len(depth_image_array.shape) == 3:
            print("æ·±åº¦å›¾æ˜¯3é€šé“ï¼Œå–ç¬¬ä¸€ä¸ªé€šé“")
            depth_image_array = depth_image_array[:, :, 0]
        
        # è½¬æ¢ä¸ºæµ®ç‚¹æ•°å¹¶ä½¿ç”¨æ­£ç¡®çš„æ·±åº¦æ¯”ä¾‹è½¬æ¢ä¸ºç±³
        # RealSense D405çš„æ·±åº¦æ¯”ä¾‹æ˜¯0.0001
        depth_scale = 0.0001
        depth_image_array = depth_image_array.astype(np.float32) * depth_scale
        
        # 4. åˆå§‹åŒ–æ£€æµ‹å™¨
        categories_to_find = ['cup']
        segmentator = YOLOSegmentator()
        
        # 5. æ£€æµ‹å’Œåˆ†å‰²æ¯å­
        print(f"\nğŸ” å¼€å§‹æ£€æµ‹æ¯å­...")
        print(f"  å›¾åƒå°ºå¯¸: {color_image.shape}")
        print(f"  æ£€æµ‹ç±»åˆ«: {categories_to_find}")
        print(f"  ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
        
        result = segmentator.detect_and_segment_all(
            image=color_image,
            categories=categories_to_find,
            save_result=False,
            conf=conf_threshold
        )
        
        # 6. æ£€æŸ¥æ£€æµ‹ç»“æœ
        if not result['success']:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': None,
                'error_message': "æ£€æµ‹å¤±è´¥ï¼šæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“"
            }
        
        if 'objects' not in result or len(result['objects']) == 0:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': None,
                'error_message': "æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“"
            }
        
        # 7. å¤„ç†ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„æ¯å­
        cup_obj = result['objects'][0]
        print(f"\nğŸµ æ£€æµ‹åˆ°æ¯å­:")
        print(f"  ç±»åˆ«: {cup_obj['class']}")
        print(f"  ç½®ä¿¡åº¦: {cup_obj['confidence']:.2f}")
        print(f"  è¾¹ç•Œæ¡†: {cup_obj['bbox_xyxy']}")
        
        # 8. æ£€æŸ¥æ˜¯å¦æœ‰æ©ç 
        if cup_obj['mask'] is None:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': cup_obj,
                'error_message': "æœªè·å–åˆ°æ¯å­çš„åˆ†å‰²æ©ç "
            }
        
        print(f"  æ©ç å°ºå¯¸: {cup_obj['mask'].shape}")
        
        # 9. è·å–ç›¸æœºå†…å‚
        intrinsics = cam.get_camera_matrix()
        if intrinsics is None:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': cup_obj,
                'error_message': "æ— æ³•è·å–ç›¸æœºå†…å‚"
            }
        
        # 10. æ‰‹çœ¼æ ‡å®šçŸ©é˜µï¼ˆä»left_calibration.txtè¯»å–ï¼‰
        calibration_file = 'left_calibration.txt'
        if not os.path.exists(calibration_file):
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': cup_obj,
                'error_message': f"æ‰‹çœ¼æ ‡å®šæ–‡ä»¶ä¸å­˜åœ¨: {calibration_file}"
            }
        
        # è¯»å–æ‰‹çœ¼æ ‡å®šçŸ©é˜µ
        with open(calibration_file, 'r') as f:
            content = f.read().strip()
        
        # è§£æçŸ©é˜µæ•°æ® - å¤„ç†åµŒå¥—æ–¹æ‹¬å·æ ¼å¼
        # ç§»é™¤æœ€å¤–å±‚çš„æ–¹æ‹¬å·
        if content.startswith('[[') and content.endswith(']]'):
            content = content[1:-1]  # ç§»é™¤æœ€å¤–å±‚çš„æ–¹æ‹¬å·
        
        # æŒ‰è¡Œåˆ†å‰²
        lines = content.split('\n')
        matrix_data = []
        for line in lines:
            line = line.strip()
            if line.startswith('[') and line.endswith(']'):
                # ç§»é™¤æ–¹æ‹¬å·å¹¶åˆ†å‰²
                line = line[1:-1]
                row = [float(x.strip()) for x in line.split()]
                matrix_data.append(row)
        
        if len(matrix_data) != 4:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': cup_obj,
                'error_message': f"æ‰‹çœ¼æ ‡å®šçŸ©é˜µæ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›4x4çŸ©é˜µï¼Œå®é™…{len(matrix_data)}x{len(matrix_data[0]) if matrix_data else 0}"
            }
        
        hand_eye_matrix = np.array(matrix_data)
        
        # 11. ä¼°è®¡æ¯å­ä½å§¿
        print(f"\nğŸ“ å¼€å§‹ä½å§¿ä¼°è®¡...")
        pose, T_object2cam = mask2pose(
            mask=cup_obj['mask'],
            depth_image=depth_image_array,
            color_image=color_image,
            intrinsics=intrinsics,
            T_cam2base=None,  # åœ¨ç›¸æœºåæ ‡ç³»ä¸­è®¡ç®—
            object_class=cup_obj['class']
        )
        
        if pose is None or T_object2cam is None:
            return {
                'success': False,
                'pose': None,
                'pose_matrix': None,
                'detection_info': cup_obj,
                'error_message': "ä½å§¿ä¼°è®¡å¤±è´¥"
            }
        
        print(f"  ç›¸æœºåæ ‡ç³»ä¸‹ä½ç½®: [{pose[0]:.3f}, {pose[1]:.3f}, {pose[2]:.3f}] ç±³")
        print(f"  ç›¸æœºåæ ‡ç³»ä¸‹å§¿æ€: [{pose[3]:.1f}Â°, {pose[4]:.1f}Â°, {pose[5]:.1f}Â°]")
        
        # 12. è½¬æ¢åˆ°æœºæ¢°è‡‚åŸºåæ ‡ç³»
        # å‡è®¾æœºæ¢°è‡‚å½“å‰ä½å§¿ä¸ºå•ä½çŸ©é˜µï¼ˆå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
        robot_pose_matrix = np.eye(4)
        robot_pose_matrix = robot_matrix
        pose_matrix = robot_pose_matrix @ hand_eye_matrix @ T_object2cam
        
        # 13. è½¬æ¢ä¸ºæœºæ¢°è‡‚åæ ‡ç³»ä¸‹çš„ä½å§¿
        from scipy.spatial.transform import Rotation as R
        rx, ry, rz = R.from_matrix(pose_matrix[:3, :3]).as_euler('xyz', degrees=True)
        x, y, z = pose_matrix[:3, 3] * 1000.0  # è½¬æ¢ä¸ºæ¯«ç±³
        ry = ry + 90  # æ ¹æ®å®é™…éœ€è¦è°ƒæ•´
        
        final_pose = [x, y, z, rx, ry, rz]
        
        print(f"\nâœ… ä½å§¿ä¼°è®¡å®Œæˆ:")
        print(f"  æœºæ¢°è‡‚åæ ‡ç³»ä¸‹ä½ç½®: [{x:.1f}, {y:.1f}, {z:.1f}] æ¯«ç±³")
        print(f"  æœºæ¢°è‡‚åæ ‡ç³»ä¸‹å§¿æ€: [{rx:.1f}Â°, {ry:.1f}Â°, {rz:.1f}Â°]")
        
        # 14. å¯è§†åŒ–ä½å§¿ï¼ˆå¯é€‰ï¼‰
        try:
            draw_pose_axes(color_image, intrinsics, T_object2cam)
        except Exception as e:
            print(f"ä½å§¿å¯è§†åŒ–å¤±è´¥: {e}")
        
        # 15. è¿”å›ç»“æœ
        return {
            'success': True,
            'pose': final_pose,
            'pose_matrix': pose_matrix,
            'detection_info': {
                'class': cup_obj['class'],
                'confidence': cup_obj['confidence'],
                'bbox_xyxy': cup_obj['bbox_xyxy'],
                'mask_shape': cup_obj['mask'].shape,
                'camera_pose': pose,
                'camera_pose_matrix': T_object2cam
            },
            'error_message': None
        }
        
    except Exception as e:
        return {
            'success': False,
            'pose': None,
            'pose_matrix': None,
            'detection_info': None,
            'error_message': f"å‡½æ•°æ‰§è¡Œå‡ºé”™: {str(e)}"
        }
    finally:
        # é‡Šæ”¾ç›¸æœºèµ„æº
        try:
            cam.release()
        except:
            pass


def test_with_test_images():
    """
    ä½¿ç”¨testæ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡æµ‹è¯•å‡½æ•°
    """
    print("ğŸ§ª å¼€å§‹æµ‹è¯•æ¯å­æ£€æµ‹å’Œä½å§¿ä¼°è®¡å‡½æ•°...")
    
    # æµ‹è¯•å›¾ç‰‡è·¯å¾„
    rgb_path = 'right_pic/color.png'
    depth_path = 'right_pic/depth.png'
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(rgb_path):
        print(f"âŒ RGBå›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {rgb_path}")
        return
    
    if not os.path.exists(depth_path):
        print(f"âŒ æ·±åº¦å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {depth_path}")
        return
    
    print(f"ğŸ“ ä½¿ç”¨æµ‹è¯•å›¾ç‰‡:")
    print(f"  RGB: {rgb_path}")
    print(f"  æ·±åº¦: {depth_path}")
    
    # è°ƒç”¨æ£€æµ‹å‡½æ•°
    result = detect_cup_pose(rgb_path, depth_path)
    
    # è¾“å‡ºç»“æœ
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"  æˆåŠŸ: {result['success']}")
    
    if result['success']:
        print(f"  æ¯å­ä½å§¿: {result['pose']}")
        print(f"  æ£€æµ‹ä¿¡æ¯: {result['detection_info']}")
    else:
        print(f"  é”™è¯¯ä¿¡æ¯: {result['error_message']}")
    
    return result


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_with_test_images()